{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mrunal Reddy Ragi\n",
        "\n",
        "\n",
        "Week 09 Machne Learning Assignment - Scikit Learn"
      ],
      "metadata": {
        "id": "IHOqAA30leJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this week’s assignment, you are required to investigate the accuracy-computation time tradeoffs of the different optimization algorithms (solvers) that are available for fitting linear regression models in Scikit-Learn. Using the code shared via the Python notebook (part of this week’s uploads archive) where the use of logistic regression was demonstrated, complete the following operations:\n",
        "\n",
        "1. Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\n",
        "\n",
        "The Random Forest model without cross-validation (RandomForest_noCV) establishes 0.9993 training accuracy thus reaching nearly perfect scores in tests. The model demonstrated exceptional ability to memorize training data based on its high training accuracy of 0.9993. A test performance of 0.686 illustrated heavy overfitting occurred. The model had an outstanding performance on training data yet showed weak abilities to predict new data.\n",
        "\n",
        "Multiple Logistic Regression models with penalties (L1 regularization or LASSO) applied through various C hyperparameter adjustments achieved balanced training and testing accuracy results. The basic logistic regression model reached training accuracy at 0.7333 with testing accuracy at 0.718 thus showing a moderate performance while maintaining acceptable generalization. L1 regularization with different C values did not enhance model performance but showed its capability to manage model complexity. A logistic regression model with L1 regularization achieved its best results with a training accuracy of 0.7347 and a test accuracy of 0.718 when using C=10. Cross-validation produced slightly worse test accuracy of **0.708** and **0.714** when selecting the optimal hyperparameters (Logistic_L1_C_auto and Logistic_SL1_C_auto) while offering a structured method for parameter selection.\n",
        "\n",
        "RandomForest_CV achieved better test accuracy than its non-cross-validated counterpart. The process of adjusting hyperparameters for estimators and maximum features reduced overfitting and enhanced generalization capabilities of the model. The Random Forest model achieved better performance than non-cross-validated versions yet it failed to outperform the top-performing logistic regression models during test accuracy measurements.\n",
        "\n",
        "The basic logistic regression model together with the L1-regularized logistic regression model with C=10 proved to be the most effective models because they maintained consistent test accuracy levels of approximately 0.718. Simpler models possessing capacity to resist overfitting also maintain strong generalization abilities according to this outcome. The Random Forest model achieved high training accuracy but it declined due to overfitting which stands out as a key assessment criterion for model evaluation."
      ],
      "metadata": {
        "id": "Gv51Nckjlki1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Next, fit a series of logistic regression models, without regularization. Each model should use the same set of predictors (all of the relevant predictors in the dataset) and should use the entire dataset, rather than a fraction of it. Use a randomly chosen 80% proportion of observations for training and the remaining for checking the generalizable performance (i.e., performance on the holdout subset). Be sure to ensure that the training and holdout subsets are identical across all models. Each model should choose a different solver.\n",
        "\n",
        "3. Compare the results of the models in terms of their accuracy (use this as the performance metric to assess generalizability error on the holdout subset) and the time taken (use appropriate timing function). Summarize your results via a table with the following structure:"
      ],
      "metadata": {
        "id": "deyN8srmlvIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LWwy7OzfjiuT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from patsy import dmatrices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./PatientAnalyticFile.csv')\n",
        "\n",
        "# Create mortality variable\n",
        "data['mortality'] = np.where(data['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "# Convert dateofBirth to date and calculate age in year\n",
        "data['DateOfBirth'] = pd.to_datetime(data['DateOfBirth'])\n",
        "data['Age_years'] = (pd.to_datetime('2015-01-01') - data['DateOfBirth']).dt.days / 365.25\n",
        "\n",
        "# Define variables to be removed and build formula for model\n",
        "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
        "               'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "vars_left = set(data.columns) - set(vars_remove)\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)"
      ],
      "metadata": {
        "id": "TanCELrRl4Rh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y, X = dmatrices(formula, data, return_type='dataframe')"
      ],
      "metadata": {
        "id": "6SO6vuafl7tR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(Y), test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "cX3hTRQul9iw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
        "results = []"
      ],
      "metadata": {
        "id": "Cii3XPWQl-uT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in solvers:\n",
        "    try:\n",
        "        # Initialize the model\n",
        "        clf = linear_model.LogisticRegression(solver=solver, max_iter=5000)\n",
        "\n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Fit the model\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate accuracies\n",
        "        train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
        "        test_accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
        "        time_taken = end_time - start_time\n",
        "\n",
        "        # Store results\n",
        "        results.append([solver, train_accuracy, test_accuracy, time_taken])\n",
        "    except Exception as e:\n",
        "        # Handle solver-related errors\n",
        "        results.append([solver, \"Error\", \"Error\", str(e)])\n",
        "\n",
        "# Create a results DataFrame\n",
        "results_df = pd.DataFrame(results, columns=['Solver used', 'Training subset accuracy',\n",
        "                                            'Holdout subset accuracy', 'Time taken (seconds)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT_wEm7qmAw_",
        "outputId": "4225a7b4-484b-4064-8c31-edb4c3ca9453"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irljgME7mFPL",
        "outputId": "52370341-6e0b-4d41-97c1-aeb0e6cecb06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Solver used  Training subset accuracy  Holdout subset accuracy  \\\n",
            "0   liblinear                  0.747938                  0.73625   \n",
            "1       lbfgs                  0.748125                  0.73600   \n",
            "2   newton-cg                  0.748125                  0.73625   \n",
            "3         sag                  0.748062                  0.73625   \n",
            "4        saga                  0.748125                  0.73625   \n",
            "\n",
            "   Time taken (seconds)  \n",
            "0              0.115088  \n",
            "1              1.903464  \n",
            "2              0.335046  \n",
            "3             62.870919  \n",
            "4             57.209683  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "The performance levels of Training Accuracy and Holdout Accuracy were nearly identical between the five solvers liblinear, lbfgs, newton-cg, sag, and saga. All solvers demonstrated similar performance during training with accuracy levels around 0.748 while showing comparable holdout accuracy rates of 0.736. All optimization algorithms used by these solvers demonstrated equal effectiveness when identifying optimal model parameters from the given dataset.\n",
        "\n",
        "The execution duration between solvers shows substantial differences even though their accuracy results match closely. The liblinear solver finished the training process in 0.115 seconds which made it the fastest among all solvers. The solver targets small-scale datasets and binary classification tasks therefore it provides an excellent solution for this problem. The execution time of the lbfgs solver reached 1.9 seconds while the newton-cg solver finished in 0.3 seconds. These algorithms show good results for true multinomial problems as they simultaneously perform competently for binary classification tasks.\n",
        "\n",
        "The solvers sag and saga demonstrated the slowest performance among all solvers because they are designed for large datasets and required 62.87 seconds and 57.21 seconds respectively to complete execution. The execution times of these solvers indicate that they might provide more power than necessary for this specific problem.\n",
        "\n",
        "The execution time of liblinear makes it the top solver because it delivers equivalent accuracy results with the minimum runtime duration. The assessment of solver performance based solely on accuracy would be inaccurate because several solvers demonstrated equivalent accuracy results. The ranking system should incorporate accuracy results with computation time measurements to select the most efficient solver when all accuracy scores are equivalent. The liblinear solver demonstrates superior performance through its high speed which makes it the most efficient option for this dataset and problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "jxH5wyWImG7-"
      }
    }
  ]
}